---
layout: post
title:  Kafka基础知识
categories: 分布式
description: kafka
keywords: 分布式, kafka
---

### **kafka简介**
kafka是一个分布式消息发布订阅系统。它最初由linkedin公司基于独特的设计实现为一个分布式提交日志系统，之后成为Apache项目的一部分。kafka系统快速、可扩展并且可持久化。它的分区特性中的可复制、可容错都是很不错的特性。

1. ##### Apache kafka与传统消息系统相比，不同之处在于：
    + 它被设计为一个分布式系统，易于向外扩展
    + 它能同时为发布和订阅提供高吞吐量
    + 它支持多订阅者，当失败时能自动平衡消费者
    + 它将消息持续化到磁盘，因此可用于批量消费

2. ##### kafka 使用的基本术语：
    + Topic：kafka 将消息分门别类，每一类消息称之为topic
    + Producer：发布的消息对象称之为消息产生者
    + Consumer：订阅消息并处理发布的消息的种子的对象称之为话题消费者
    + Broker：已发布的消息保存在一组服务器中，成为 kafka 集群。集群中每一个服务器都是一个代理（broker），消费者可以订阅一个或者多个topic，并从topic中拉取数据，从而消费这些已经发布的信息。
    + Partition：物理上分组。每一个topic可以有多个partition，partition是为了提高kafka系统的并发能力，每一个partition是一个有序的队列，partition中的每一条消息都会被分配一个有序的id（offset），kafka只保证按一个partition中的顺序将消息发送给consumer，并不保证同一topic不同partition的顺序，消息发送到哪个分区上有两种基本策略：一是采用key hash算法，一是采用round robin算法
    + Offset：消息的偏移量


在high level上来看，producer通过网络向kafka集群发送消息，同时，kafka集群可以向consumer提供这些消息，如图所示：

Client和server之间的交流通过一条简单、高性能并且不局限某种开发语言的tcp协议，除了java client之外，还有非常多的其他编程语言的client。

Topic可以看成不同消息的**类别或者信息流**，不同的消息根据topic进行分类，汇总，然后producer将不同分类的消息发往不同的topic，对于每一个topic，kafka集群维护一个**分区日志**，如图：

从上图可以看出，每一个分区都是一个顺序的，不可变的消息队列，并且可以持续添加。分区中的消息都被分配了一个序列号，称之为偏移量（offset），在每个分区中此偏移量都是唯一的。

Kafka集群可以保存所有发布的消息，直到他们过期，过期消息无论有没有被消费都会被清除以释放空间，因此kafka可以高效持久的保存大量的数据.

实际上消费者所持有的仅有的**元数据**就是偏移量（offset），也就是消费者在这个log中的位置。这个偏移量由**消费者控制**：正常情况下当消费者消费消息的时候，偏移量也线性的增加，但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。

##### 可以看到这种设计对消费者来说操作自如，一个消费者的操作不会影响其他消费者对此log的处理。

Kafka中采用分区（partition）的设计来存储数据，**主要有以下几个目的**：一是可以处理更多的消息，不受单台服务器的限制，topic拥有多个分区意味着它可以不受限的处理更多的数据;第二，分区可以作为并行处理的单元。

Kafka的**分布式设计**：日志的partition分布在kafka集群中的servers上，每个服务器都可以处理数据以及共享分区的需求，每个分区都可以进行备份，进行备份的servers数目是可以配置的，以提高容错能力。每个partitions拥有一台称为leader的server，同时拥有0或者多个称为followers的servers，leader处理所有有关partition的读写请求，follower随之对leader进行备份，如果leader宕机，followers其中之一将被推举为新的leader。一台服务器可能同时是一个分区的leader，另一个分区的follower，这样可以实现负载均衡，避免所有的请求都只让一台或者某几台服务器处理。

Kafka生产者往某个topic上发布消息，生产者也负责选择发布到此topic的哪一个分区，最简单的方法是从分区列表中轮流选择，也可以根据某种算法依照权重选择分区。

消费者，通常，**消息模型**可以分为两种，一是**队列**，二是**发布订阅**，队列的处理方式是一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。在发布订阅模型中，消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。Kafka为这两种模型提供了单一的消费者抽象模型：**消费者组（consumer group）**。消费者用一个消费组名称标记自己。一个发布在topic上消息被分发给此消费者组中的一个消费者，假如所有的消费者都在一个组中，那么这就变成了queue模型，假如所有的消费者都在不同的组中，那么就完全变成了发布订阅模型。更通用的，我们可以创建一些消费者组作为逻辑上的订阅者，每个组包含数目不等的消费者，一个组内多个消费者可以用来扩展性能和容错。如下图所示：

正如传统的消息系统一样，kafka保证消息的顺序不变。传统的队列模型保持消息，并且保证消息的先后顺序不变，但是，尽管服务器保证了消息的顺序，消息还是异步的发送给各个消费者，消费者收到消息的先后顺序就不能保证了，这也意味着并行消费将不能保证消息的先后顺序。用过传统消息系统的同学肯定清楚，消息的顺序处理很让人头疼。如果只让一个消费者处理消息，又违背了并行处理的初衷。在这一点上kafka做的更好，尽管并没有完全解决上述问题。Kafka采用了一种分而治之的策略：分区。因为topic分区中消息只能由消费者组中的唯一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也仅仅是保证topic的一个分区顺序处理，不能保证跨分区的消息的先后处理顺序。所以如果想要顺序的处理topic的所有消息，那就只能提供一个分区。

3. ##### Kafka的保证：
    + 生产者发送到一个特定的topic的分区上的消息将会按照他们发送的顺序依次加入
    + 消费者收到的消息也是顺序的
    + 如果一个topic配置了复制因子N，那么可以允许N-1服务器宕掉而不丢失任何已经增加的消息

4. ##### Kafka的常用场景：
    + 消息系统，可以与activemq、rabbitmq等消息系统对比
    + 站点的用户活动追踪，用来记录用户的页面浏览、搜索、点击等
    + 操作审计，用户、管理员的网站操作监控
    + 日志聚合，收集数据，集中处理

5. ##### 流处理
    + Event sourcing
    + Commit log

### 二、 Kafka安装及使用
##### 1. 下载代码
下载并解压，下载地址http://kafka.apache.org/downloads.html
```bash
$ tar –zxvf kafka_version.tgz
$ cd kafka_version
```
##### 2. 启动服务
Kafka使用zookeeper所以你可能需要先安装[zookeeper](url=https://zookeeper.apache.org/)，你可以使用kafka中打包好的脚本或者一个已经配置好的zookeeper
```bash
$ bin/zookeeper-server-start.sh config/zookeeper.properties
/* 启动kafka */
$ bin/kafka-server-start.sh config/server.propertie
```

##### 3. 创建一个topic
Topic的名字为test，只有一个分区和一个备份
```bash
/* 创建 */
$ bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic test
/* 查询 */
$ bin/kafka-topics.sh –list –zookeeper localhost:2181
```
除了手工创建topic，你也可以配置你的broker当发布一个不存在的topic时自动创建topic

##### 4. 发送消息
Kafka提供了一个命令行的工具，可以从输入文件或者命令行中读取消息并发送给kafka集群，每一行是一条消息
```bash
$ bin/kafka-sonsole-sonsumer.sh –zookeeper localhost:2181 –topic test –from-beginning
$ This is a message
$ This is another message
```
这些命令行工具有很多的选项，你可以查看他们的文档来了解更多的功能。

##### 5. 消费消息
Kafka也提供了一个消费消息的命令行工具
```bash
$ bin/kafka-console-consumer.sh –zookeeper loalhost:2181 –topic test –from-beginniing
```
这些命令行工具有很多的选项，你可以查看他们的文档来了解更多的功能。

##### 6. 设置多个broker
目前我们运行在一个broker上，现在我们设置多个broker
```bash
// 首先为每一个broker创建一个配置文件
cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties

// 修改文件 Server-1.properties
broker.id=1
port=9093
log.dir=/tmp/kafka-logs-1
// 修改文件 Server-2.properties
broker.id=1
port=9094
log.dir=/tmp/kafka-logs-2

// Broker.id属性不可重复，为了在一台服务器上启动两个broker，改了一下port
// 启动新建的broker
bin/kafka-server-start.sh config/server-1.properties &
bin/kafka-server-start.sh config/server-2.properties &

// 创建一个topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
// 运行describe topics命令查看topic信息:
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic

// 发送消息
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
// 消费消息
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic

// 测试一下容错. 干掉leader,也就是Broker 1
ps | grep server-1.properties
kill -9 pid

// Leader被切换到一个follower上节, 点 1 不会被列在isr中了，因为它被kill了:
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
// 但是消息并没有丢失：
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic my-replicated-topic
```

### 三、 Kafka 操作API
+ ##### Producer
    + Java
        1. Producer：
        2. 自定义partition规则：
    + Flume
+ ##### 高级消费api
  + ##### 实现步骤：
    + 创建kafka配置
    + 利用consumer拉取数据，可以设置拉取的线程数
    + 利用多线程来处理拉取的数据
    + 关闭consumer
  + ##### 高级API的优点：
    + 实现简单
    + 不需要自行去管理offset，系统通过zookeeper自行管理
    + 不需要管理分区、副本等信息，系统自动管理
  + ##### 缺点：
    + 不能自行控制offset
    + 不能细化控制如分区、副本, zk等

  ```java
  package com.sohu.adrd.kafka.consumer;
  import kafka.consumer.ConsumerConfig;
  import kafka.consumer.KafkaStream;
  import java.util.HashMap;
  import java.util.List;
  import java.util.Map;
  import java.util.Properties;
  import java.util.concurrent.ExecutorService;
  import java.util.concurrent.Executors;
  import java.util.concurrent.TimeUnit;

  /* Created by zhongnanhuang209074 on 2016/7/27. */

  public class HighLevelConsumer {
      private final kafka.javaapi.consumer.ConsumerConnector consumer;
      private final String topic;
      private ExecutorService executor;
      public HighLevelConsumer(String a_zookeeper, String a_groupId, String a_topic) {
          consumer = kafka.consumer.Consumer.createJavaConsumerConnector(
                          createConsumerConfig(a_zookeeper, a_groupId));
          this.topic = a_topic;
      }

      public void shutdown() {
          if (consumer != null) consumer.shutdown();
          if (executor != null) executor.shutdown();
          try {
                  if (!executor.awaitTermination(5000, TimeUnit.MILLISECONDS)) {
                          System.out.println("Timed out waiting for consumer threads to shut down, exiting uncleanly");
                      }
              } catch (InterruptedException e) {
                  System.out.println("Interrupted during shutdown, exiting uncleanly");
              }
     }

      public void run(int a_numThreads) {
          Map<String, Integer> topicCountMap = new HashMap<String, Integer>();
          topicCountMap.put(topic, new Integer(a_numThreads));
          Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);
          List<KafkaStream<byte[], byte[]>> streams = consumerMap.get(topic);
          // now launch all the threads
          //
          executor = Executors.newFixedThreadPool(a_numThreads);
          // now create an object to consume the messages
          //
          int threadNumber = 0;
          for (final KafkaStream stream : streams) {
                  executor.submit(new ConsumerTest(stream, threadNumber));
                  threadNumber++;
              }
      }
      private static ConsumerConfig createConsumerConfig(String a_zookeeper, String a_groupId) {
          Properties props = new Properties();
          props.put("zookeeper.connect", a_zookeeper);
          props.put("group.id", a_groupId);
          props.put("zookeeper.session.timeout.ms", "400");
          props.put("zookeeper.sync.time.ms", "200");
          props.put("auto.commit.interval.ms", "1000");
          return new ConsumerConfig(props);
      }
      public static void main(String[] args) {
          String zooKeeper = args[0];
          String groupId = args[1];
          String topic = args[2];
          int threads = Integer.parseInt(args[3]);
          HighLevelConsumer example = new HighLevelConsumer(zooKeeper, groupId, topic);
          example.run(threads);
          try {
                  Thread.sleep(10000);
          } catch (InterruptedException ie) {
          }
          example.shutdown();
      }
  }
```

+ ##### 低级消费api
  + ##### 实现步骤：
    + 查找到topic、partition的leader
    + 查找到读取的offset值
    + 读取数据
    + 出现异常重新找newleader
    + 关闭

  ```java
  package com.sohu.adrd.kafka.consumer;
  import kafka.api.FetchRequest;
  import kafka.api.FetchRequestBuilder;
  import kafka.api.PartitionOffsetRequestInfo;
  import kafka.common.ErrorMapping;
  import kafka.common.TopicAndPartition;
  import kafka.javaapi.*;
  import kafka.javaapi.consumer.SimpleConsumer;
  import kafka.message.MessageAndOffset;
  import java.nio.ByteBuffer;
  import java.util.ArrayList;
  import java.util.Collections;
  import java.util.HashMap;
  import java.util.List;
  import java.util.Map;

  /* Created by zhongnanhuang209074 on 2016/7/27. */

  public class LowLevelConsumer {
      public static void main(String args[]) {
          LowLevelConsumer example = new LowLevelConsumer();
          long maxReads = Long.parseLong(args[0]);
          String topic = args[1];
          int partition = Integer.parseInt(args[2]);
          List<String> seeds = new ArrayList<String>();
          seeds.add(args[3]);
          int port = Integer.parseInt(args[4]);
          try {
              example.run(maxReads, topic, partition, seeds, port);
          } catch (Exception e) {
              System.out.println("Oops:" + e);
              e.printStackTrace();
          }
      }
      private List<String> m_replicaBrokers = new ArrayList<String>();
      public LowLevelConsumer() {
          m_replicaBrokers = new ArrayList<String>();
      }
      public void run(long a_maxReads, String a_topic, int a_partition, List<String> a_seedBrokers, int a_port) throws Exception {
          // find the meta data about the topic and partition we are interested in
          //
          PartitionMetadata metadata = findLeader(a_seedBrokers, a_port, a_topic, a_partition);
          if (metadata == null) {
              System.out.println("Can't find metadata for Topic and Partition. Exiting");
              return;
          }
          if (metadata.leader() == null) {
              System.out.println("Can't find Leader for Topic and Partition. Exiting");
              return;
          }
          String leadBroker = metadata.leader().host();
          String clientName = "Client_" + a_topic + "_" + a_partition;
          SimpleConsumer consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName);
          long readOffset = getLastOffset(consumer,a_topic, a_partition, kafka.api.OffsetRequest.EarliestTime(), clientName);
          int numErrors = 0;
          while (a_maxReads > 0) {
              if (consumer == null) {
                  consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64 * 1024, clientName);
              }
              FetchRequest req = new FetchRequestBuilder()
              .clientId(clientName)
              .addFetch(a_topic, a_partition, readOffset, 100000) // Note: this fetchSize of 100000 might need to be increased if large batches are written to Kafka
              .build();
              FetchResponse fetchResponse = consumer.fetch(req);
              if (fetchResponse.hasError()) {
                  numErrors++;
                  // Something went wrong!
                  short code = fetchResponse.errorCode(a_topic, a_partition);
                  System.out.println("Error fetching data from the Broker:" + leadBroker + " Reason: " + code);
                  if (numErrors > 5) break;
                  if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                      // We asked for an invalid offset. For simple case ask for the last element to reset
                      readOffset = getLastOffset(consumer,a_topic, a_partition, kafka.api.OffsetRequest.LatestTime(), clientName);
                      continue;
                  }
                  consumer.close();
                  consumer = null;
                  leadBroker = findNewLeader(leadBroker, a_topic, a_partition, a_port);
                  continue;
              }
              numErrors = 0;
              long numRead = 0;
              for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(a_topic, a_partition)) {
                  long currentOffset = messageAndOffset.offset();
                  if (currentOffset < readOffset) {
                      System.out.println("Found an old offset: " + currentOffset + " Expecting: " + readOffset);
                      continue;
                  }
                  readOffset = messageAndOffset.nextOffset();
                  ByteBuffer payload = messageAndOffset.message().payload();
                  byte[] bytes = new byte[payload.limit()];
                  payload.get(bytes);
                  System.out.println(String.valueOf(messageAndOffset.offset()) + ": " + new String(bytes, "UTF-8"));
                  numRead++;
                  a_maxReads--;
              }
              if (numRead == 0) {
                  try {
                      Thread.sleep(1000);
                  } catch (InterruptedException ie) {
                  }
              }
          }
          if (consumer != null) consumer.close();
      }
      public static long getLastOffset(SimpleConsumer consumer, String topic, int partition,
  long whichTime, String clientName) {
          TopicAndPartition topicAndPartition = new TopicAndPartition(topic, partition);
          Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
          requestInfo.put(topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1));
          kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(
                  requestInfo, kafka.api.OffsetRequest.CurrentVersion(), clientName);
          OffsetResponse response = consumer.getOffsetsBefore(request);
          if (response.hasError()) {
              System.out.println("Error fetching data Offset Data the Broker. Reason: " + response.errorCode(topic, partition) );
              return 0;
          }
          long[] offsets = response.offsets(topic, partition);
          return offsets[0];
      }
      private String findNewLeader(String a_oldLeader, String a_topic, int a_partition, int a_port) throws Exception {
          for (int i = 0; i < 3; i++) {
              boolean goToSleep = false;
              PartitionMetadata metadata = findLeader(m_replicaBrokers, a_port, a_topic, a_partition);
              if (metadata == null) {
                  goToSleep = true;
              } else if (metadata.leader() == null) {
                  goToSleep = true;
              } else if (a_oldLeader.equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                  // first time through if the leader hasn't changed give ZooKeeper a second to recover
                  // second time, assume the broker did recover before failover, or it was a non-Broker issue
                  //
                  goToSleep = true;
              } else {
                  return metadata.leader().host();
              }
              if (goToSleep) {
                  try {
                      Thread.sleep(1000);
                  } catch (InterruptedException ie) {
                  }
              }
          }
          System.out.println("Unable to find new leader after Broker failure. Exiting");
          throw new Exception("Unable to find new leader after Broker failure. Exiting");
      }
      private PartitionMetadata findLeader(List<String> a_seedBrokers, int a_port, String a_topic, int a_partition) {
          PartitionMetadata returnMetaData = null;
          loop:
          for (String seed : a_seedBrokers) {
              SimpleConsumer consumer = null;
              try {
                  consumer = new SimpleConsumer(seed, a_port, 100000, 64 * 1024, "leaderLookup");
                  List<String> topics = Collections.singletonList(a_topic);
                  TopicMetadataRequest req = new TopicMetadataRequest(topics);
                  kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);
                  List<TopicMetadata> metaData = resp.topicsMetadata();
                  for (TopicMetadata item : metaData) {
                      for (PartitionMetadata part : item.partitionsMetadata()) {
                          if (part.partitionId() == a_partition) {
  returnMetaData = part;
                              break loop;
                          }
                      }
                  }
              } catch (Exception e) {
                  System.out.println("Error communicating with Broker [" + seed + "] to find Leader for [" + a_topic
                          + ", " + a_partition + "] Reason: " + e);
              } finally {
                  if (consumer != null) consumer.close();
              }
          }
          if (returnMetaData != null) {
              m_replicaBrokers.clear();
              for (kafka.cluster.Broker replica : returnMetaData.replicas()) {
                  m_replicaBrokers.add(replica.host());
              }
          }
          return returnMetaData;
      }
  }
  ```

+ ##### Strom消费
  + ##### 实现步骤：
    + 进行kafkaspout的配置
    + 声明kafkspout
  + ##### 使用注意事项:
    + 存在ack机制，如果不想使用ack机制有两种改进方法：一重写kafkaspout，二设置ack个数为0
  
  ```java
  package com.sohu.adlog.push.storm.spout;
  import backtype.storm.spout.SchemeAsMultiScheme;
  import com.sohu.adlog.push.storm.utils.Constant;
  import storm.kafka.*;
  import java.util.ArrayList;
  import java.util.List;
    /**
   * Created by zhongnanhuang209074 on 2015/12/17.
   */
    public class DataStreamKafkaSpout {
      private SpoutConfig spoutConfig = null;
      private String zks = Constant.conf.getZkhosts();
      private String topic = Constant.topic;
      private String groupid = Constant.groupId;
      private String zkRoot = Constant.zkRoot;
      private int zkPort = Constant.zkPort;
      private boolean local = false;//是否为本地模式，本地模式需要显示的配置zkservers和zkport
      public DataStreamKafkaSpout(){
          this.init();
      }
      private void init(){
          BrokerHosts hosts = new ZkHosts(zks);
          spoutConfig = new SpoutConfig(hosts,topic,zkRoot,groupid);
          spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());//解析kafka的数据类配置
          spoutConfig.forceFromStart = Constant.forceFromStart;//判断是否需要从头开始读，true表示从头开始读，false表示从当前开始读
          if (local) {
              spoutConfig.zkServers = this.builtServers(zks);
              spoutConfig.zkPort = zkPort;
          }
      }
      private List<String> builtServers(String zks){
          List<String> servers = new ArrayList<String>();
          String hosts[] = zks.split(",");
          for(String str : hosts){
              String temp[] = str.split(":");
              servers.add(temp[0]);
          }
          return servers;
      }
      public KafkaSpout createKafkaSpout(){
          return new KafkaSpout(spoutConfig);
      }
      public void setLocal(boolean flag){
          this.local = flag;
      }
  }
  ```

+ ##### Spark消费
  + 高级api
  + 低级api
+ ##### Hadoop消费

### 四、 Kafka配置参数

### 五、 Kafka与zookeeper
Kafka将元数据信息保存在zookeeper中，发送给topic本身的信息不会发送到zookeeper上。Kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。Broker会在zookeeper上注册并保持相关的元数据（topic、partition信息等）更新；客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整，这样就保证了添加或去除broker时，各broker间仍然能够自动实现负载均衡，这里的客户端指的是kafka的消息生产端和消息消费端；broker端使用zookeeper来注册broker信息，以及监测partition leader存活性；consumer端使用zookeeper来注册consumer信息，其中包括partition列表等，同时也用来发现broker列表，并和partition leader建立socket连接，并获取消息；zookeeper和producer没有建立关系，只和brokers、consumer建立关系实现负载均衡，即同一个consumer group中的consumer可以实现负载均衡。

### 六、 其他消息队列工具
1. Activemq
2. Rabbitmq
3. Zeromq

### 七、 开发问题及解决方案

### 八、 其他
